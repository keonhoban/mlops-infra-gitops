# airflow-dev values.yaml

airflow:
  images:
    airflow:
      tag: v1.3.3

  # 기준값: 환경별 airflow 도메인
  global:
    airflowHost: airflow.local  # ⬅️ 모든 host 관련 값의 기준값

  dags:
    gitSync:
      enabled: true
      repo: git@github.com:keonhoban/airflow-dags-dev.git
      branch: main
      subPath: dags
      depth: 1
      wait: 10
      rev: HEAD
      sshKeySecret: airflow-git-ssh-secret

  # Airflow config 직접 정의 (공식 Helm Chart의 config 블록)
  config:
    AIRFLOW__WEBSERVER__WEB_SERVER_BASE_URL:
      value: "http://airflow.local"  # ⬅️ global.airflowHost 기준값

  apiSecretKeySecretName: airflow-dev-api-secret-key
  jwtSecretName: airflow-dev-jwt-secret
  apiSecretKey: ~
  jwtSecret: ~

  # Fernet Key / Metadata DB 관련 시크릿
  fernetKeySecretName: airflow-fernet-dev-secret

  data:
    metadataSecretName: airflow-db-dev-secret

  # Scheduler 설정 (Anchor 정의)
  scheduler: &dev_scheduler
    env:
      - name: RELOAD_SECRET_TOKEN
        valueFrom:
          secretKeyRef:
            name: fastapi-token-dev-secret
            key: RELOAD_SECRET_TOKEN

      - name: SLACK_WEBHOOK_URL
        valueFrom:
          secretKeyRef:
            name: slack-webhook-dev-secret
            key: SLACK_WEBHOOK_URL

      - name: MLFLOW_TRACKING_URI
        value: "http://mlflow-dev-service.mlflow-dev.svc.cluster.local:5000"
      - name: FASTAPI_RELOAD_URL
        value: "http://fastapi-dev-service.fastapi-dev.svc.cluster.local"
      - name: AIRFLOW__LOGGING__REMOTE_LOGGING
        value: "True"
      - name: AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER
        value: "s3://mlflow-artifacts-keonho/dev/airflow-logs"
      - name: AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID
        value: "aws_default"
      - name: AWS_REGION
        value: ap-northeast-2
      - name: AWS_DEFAULT_REGION
        value: ap-northeast-2

    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"
      limits:
        cpu: "1"
        memory: "1Gi"

    extraVolumes:
      - name: aws-credentials
        secret:
          secretName: aws-credentials-secret

      - name: triton-model-repo
        persistentVolumeClaim:
          claimName: triton-model-repo-pvc

      - name: feature-store-resources
        configMap:
          name: feature-store-resources

    extraVolumeMounts:
      - name: aws-credentials
        mountPath: /home/airflow/.aws
        readOnly: true

      - name: triton-model-repo
        mountPath: /models
        readOnly: false

      - name: feature-store-resources
        mountPath: /opt/airflow/feature-store
        readOnly: true

  # Workers / DAG Processor 에 동일 anchor 사용
  workers: *dev_scheduler
  dagProcessor: *dev_scheduler

manualIngress:
  enabled: true
  createCertificate: false
  host: airflow.local
  tlsSecret: airflow-dev-tls
  tlsIssuerName: selfsigned-issuer
  ingressClassName: nginx

featureStore:
  enabled: false
  userFeaturesSchemaJson: |
    {
      "feature_set": "user_features",
      "version": "v1",
      "columns": [
        {"name": "user_id", "type": "int64"},
        {"name": "f_total_events_7d", "type": "int64"},
        {"name": "f_avg_session_sec_7d", "type": "float64"},
        {"name": "f_last_event_age_sec", "type": "int64"}
      ],
      "primary_keys": ["user_id"],
      "description": "User behavior features (7d window)"
    }
  metadataJsonJ2: |
    {
      "feature_set": "user_features",
      "version": "{{ version }}",
      "generated_at": "{{ generated_at }}",
      "source": "{{ source }}",
      "pipeline": "{{ pipeline }}",
      "schema_hash": "{{ schema_hash }}",
      "feature_uri": "{{ feature_uri }}",
      "description": "Feature Store-lite generated features for training/inference"
    }

